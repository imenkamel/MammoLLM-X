# MammoLLM-X : A Multimodal Large Language Model for Explainable Breast Cancer Diagnosis
## Dataset
The dataset used in this work is based on the publicly available [CDD-CESM](https://www.cancerimagingarchive.net/collection/cdd-cesm/) dataset, enriched with missing patient complaints generated via a Retrieval Augmented Generation (RAG) system to provide a more realistic clinical context.
## Description
MammoLLM-X is an end-to-end multimodal AI framework for breast cancer diagnosis that integrates mammography images and patient textual data, including complaints and clinical reports. The system combines image features extracted with ResNet50 and textual features from BioClinicalBERT through a transformer-based fusion mechanism for report generation and a concatenation strategy for tumor classification. It performs tumor classification via an MLP, generates automated clinical reports using a T5 decoder, and provides interpretability through LIME, highlighting important image regions and textual terms. Missing patient complaints in the public CDD-CESM dataset are generated using a customized Retrieval Augmented Generation (RAG) system, enabling a more realistic clinical context. Evaluated on the CDD-CESM dataset, MammoLLM-X achieves state-of-the-art classification accuracy and produces coherent, clinically relevant reports, offering a robust AI-assisted tool for diagnostic support and research in explainable multimodal medical AI.
